---
title: "Assignment #2: Meta-analysis of Ocean Acidification Effects on Behaviour"
output: html_document
date: "2022-10-20"
---

## UNI ID: u7141409
# i) Statistical Analysis and Interpretation
### Downloading packages
```{r}
library(pacman)
devtools::install_github("daniel1noble/orchaRd", force = TRUE) # Install the orchaRd package
pacman::p_load(readxl, tidyverse, dplyr, Rcpp, ggforce, flextable, metafor, readr, orchaRd)
```
### Task 1: generating summary statistic for each species average treatment activity
```{r}
# Importing the data as well as signing it to a variable 
getwd() # to check pathway
OA_data <- read_csv("C:/ANU study/Year 3 2022/BIOL3207/Assignment2/data/Meta-analysis_OA/OA_activitydat_20190302_BIOL3207.csv")

# Cleaning up the data 
glimpse(OA_data)
list(unique(OA_data$species)) # To check spelling errors in species
list(unique(OA_data$treatment)) # To check spelling errors in treatment

# Omitting NA in the data as they are not required for the meta-analysis 
OA <- (na.omit(OA_data))

# The n for each species 
table(OA$species)
# The n for treatments 
table(OA$treatment)

# Creating the necessary summary statistics and using flextable() function to tidy the table
OA_sum <- (OA %>%
  group_by(species, treatment) %>% 
  summarise(mean = mean(activity, na.rm = TRUE), sd = sd(activity, na.rm = TRUE),
  n = length(unique(animal_id))) %>% rename(Species = "species"))

OA_table <- flextable(OA_sum)
```
### Task 2: Merge table from task 1 with the metadata
```{r}
# This file contains the metadata and was imported
clark <- read_csv("C:/ANU study/Year 3 2022/BIOL3207/Assignment2/data/Meta-analysis_OA/clark_paper_data.csv") 

# this function is used to get two data frames and then placed in along together
metadata1 <- cbind(clark, OA_sum) 
metadata1

# Making a final metadata  for each treatment as it was instructed in task 1. 
final_meta <- pivot_wider(metadata1, names_from = treatment, names_glue = "{treatment}_{.value}", values_from = c("mean", "sd", "n"))  ### Look for a different method.. 

final_meta
```

### Task 3: Merge the output from 2 into larger meta-analysis dataset
```{r}
# This large meta-analsis dataset was imported
ocean_meta <- read_csv("C:/ANU study/Year 3 2022/BIOL3207/Assignment2/data/Meta-analysis_OA/ocean_meta_data.csv")

# This was coded to quickly observe whether the colnames were the same/ matched
dim(ocean_meta)
dim(final_meta)

## Do some renaming of colnames so they match "meta" data variable
meta <- final_meta %>% rename("oa.sd" = CO2_sd, "oa.mean" = CO2_mean, "oa.n" = CO2_n,"ctrl.sd" = control_sd,"ctrl.n" = control_n, "ctrl.mean" = control_mean)
                            
# Reorder col names based on names in meta_data_full
meta <- meta[names(ocean_meta)]

# Check columns are in same order
colnames(ocean_meta) == colnames(meta)

# Bind the two dataframes
full_final <- rbind(ocean_meta, meta)
```

### Task 4: Calculate lnRR effect size for every row of the dataframe
```{r}
full_final[1,] # to check how a row looks like

full_final <- metafor::escalc(n1i = oa.n, n2i = ctrl.n, m1i = ctrl.mean, m2i = oa.mean, sd1i = oa.sd, sd2i = ctrl.sd, data = full_final, measure = "ROM")
# yi: observed effect sizes
# vi: sampling variances

# calculating the effect size by one hand of one row to check if i got the correct calculation
13.2730^2 #176.1725
72.7890^2 #5298.239
2.9931^2 #8.958648
94.1290^2 #8860.269

(176.1725/ (5298.239*46)) + (8.958648/(8860.269*26)) #0.0007617395

# Seems like i did it wrong so retrying the escalc() function calculation 
full_final <- escalc(n1i = ctrl.n, n2i = oa.n, m1i = ctrl.mean, m2i = oa.mean, sd1i = ctrl.sd, sd2i = oa.sd, data = full_final, measure = "ROM")
# Found that I had to keep the number, mean and sd of the ctrl in the same '2' and oa in '1'
```

### Task 5: Meta-analytic model for sampling variance of lnRR - including random effect of study and obervation
```{r}
# These two following coding was to change the name to less complicated
colnames(full_final)[23] = "effect.size" 
colnames(full_final)[24] = "sampling.variance"

# Add this observation level variable which will be called residual
full_final <- full_final %>% mutate(residual = 1:n()) 

meta_model <- rma.mv(effect.size ~ 1, V = sampling.variance, method = "REML",  dfs ="contain", test="t", random = list(~1|Species, ~1|Study, ~1|residual), data = full_final)
# In this rma.va function it was effect size to 1 as a control for the "V = sampling variance". In addition, the method was REML as we wanted to calculate the lnRR meta-analytic model. The random list firstly it was Species as all species could differ and the study and residual was also added as instructed from the task. 

summary(meta_model) # From using the summary function it will present the mulivariate Meta-Analysis Model.
```
Firstly, sample variance means whether the the study of the samples are listed/ located close to the expected values. Throughout the sampling variance values, it presents that the distribution ranges in around the e-03 between e+03. The extreme was e-12 which it is likely to be an outsider as it is extremely far away from the mean absolute deviation. 

### Task 6: Findings and its meanings supported with figures
```{r, table 1}
predict(meta_model)
# This function was used to calculate the confidence intervals and prediction intervals.
```
Observing the confidence interval values it suggests that the uncertainty in a sample variable is low. This suggests that the data represents pretty accurate and reliable data of the population. Also, the small ci value demonstrates the likelyhood of getting the similar result. The way pred value is -0.0612 indicates the mean overall across the studies had negative interception. 

Furthermore, the pi (prediction interval) values presents the heterogeneity in effect size estimation across the studies.

```{r, table 2}
# This is another coding method to calculate/ measure the heterogeneity
orchaRd::i2_ml(meta_model, data = full_final)
``` 
Observing table 2, the way I2 total was 100 suggests that the heterogeneity is due to because they all do not relate/ correlate to each other. 89.57% states that the heterogeneity of the study is due to residual. 5.57% states that the heterogeneity of the study is due to different studies. 4.85% states that the heterogeneity of the study is due to species

Furthermore, the second calculation states the heterogeneity of the study. The way the I2_Total states 100% presents that all the variables specifically in the species,studies and residuals do not relate or have any significant correlation to each other thus, has high heterogeneity. The I2_Species was about 4.85% stating that the heterogeneity of the study is due to species, 5.57% due to different studies and 89.57% due to residual. 

+ This is to prepare for the orchard plot which is similar to the forest plot. 
```{r}
# creating a new rma.mv function for the forest plot
meta_model1 <- rma.mv(effect.size ~ Life.stage, V = sampling.variance, method = "REML",  dfs ="contain", test="t", random = list(~1|Species, ~1|Study, ~1|residual), data = full_final)

summary(meta_model1)
```
```{r gg-oz-gapminder, Figure 1, fig.cap = ""}
# Using the previous meta model into this plot
# Making a forest plot using the orchard method 
orchaRd::orchard_plot(meta_model1, mod = "Life.stage", group = "Study", data = full_final, xlab = "Acclimation Response Ratio", angle = 45)
# The thin black line is the prediction interval 
# The thick small black line is the confidence interval
# Mean estimate is the dot circle on the prediction line. 
# K = number samples 
# The numbers in the bracket refers to the number of studies
```
The predict() and orchaRd::i2_ml() functions were used to measure the heterogeneity in effect size estimation across the studies. According to the first calculation of the prediction intervals the 95% confidence intervals present that the interception as well as the overall meta-analytic mean across the studies was -0.0612 indicating that there is no correlation. Furthermore, the second calculation states the heterogeneity of the study. The way the I2_Total states 100% presents that all the variables specifically in the species,studies and residuals do not relate or have any significant correlation to each other thus, has high heterogeneity. The I2_Species was about 4.85% stating that the heterogeneity of the study is due to species, 5.57% due to different studies and 89.57% due to residual. 

Instead of the forest plot (Figure 1) the orchard plot was used as it gives similar results (confirmed okay by the lecturer). In this figure 1, the mean estimate (the dot circle that is on the prediction line) across the life stages of the fishes shown to be around very close to the vertical dotted line. In addition looking at the 95% confidence interval the (thick black line) suggests that all of these life stages seem to show… The prediction interval (thin black line) suggests that… For each stage the number of samples are shown as k and the number of studies plotted on figure is in brackets.

### Task 7: Funnel plot
```{r}
funnel(x = full_final$effect.size, vi = full_final$sampling.variance, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray75"), yaxis = "seinv", digits = 2, las = 1, xlab = "Correlation Coefficient (r)", atransf=tanh, legend = TRUE)
# This coding was learnt in the previous lectures/ workshop 

# delete the outliers since the yaxis are way to stretched out
plot(full_final$sampling.variance, full_final$residuals, ylim = c(0.00012, 4))

fun_a <- full_final[-c(17, 16, 497, 255, 564, 6, 562, 220, 673, 163), ] # This is specifically looking at the data and cutting the outliers. 
```
```{r gg-oz-gapminder, Figure 2, fig.cap = ""}
# Coding to present a funnel plot
funnel(x = fun_a$effect.size, vi = fun_a$sampling.variance, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray75"), yaxis = "seinv", digits = 2, las = 1, xlab = "Correlation Coefficient (r)", atransf=tanh, legend = TRUE)
```
Funnel plot (Figure 2) of the effect size sampling variance. This presents the publication bias possibility. Observing the graph, it shows that the vertical linear line is placed at 0. The shades are not seen probably because there are still quite large numbers of samples and so the shades are not seen. the shades can be seen if zoomed in. It is to visualize the correlation between the variables. The way how there is no asymmetrical distribution indicates that there is no potential publication bias.

### Task 8: Time-lag plot
```{r gg-oz-gapminder, Figure 3, fig.cap = ""}
colnames(fun_a)[3] = "year.online"
colnames(fun_a)[4] = "year.print"

# cumulative meta-analysis & mean effect size change test etc 
ggplot(fun_a, aes(y = effect.size, x = year.online, size = 1/sqrt(sampling.variance))) + geom_point(alpha = 0.3) +
    geom_smooth(method = lm, col = "red", show.legend = FALSE) + labs(x = "Publication Year",
    y = "Fisher's Z-transformed Correlation Coefficient (Zr)", size = "Precision (1/SE)") +
    theme_classic()


# Time-lag explains `r r2_time[1]*100`% of the variation in Zr
```
Figure 3: The time-lag plot presents the effect size changes throughout the time. This presents a linear line which was placed along the data where the shaded areas demonstrate the spreadness of the individuals. This provides information that the linear line is a positive slope which indicates the mean effect size increases when the sampling variance is also large. The way there is about equal distribution across the line shows that the expected publication bias as both directions was shown approximately the same. The time lag plot assesses how effect sizes may or not have changed through time. Looking at this publication bias is so that the average effect size changes on the true mean by accumulating more studies. To see if it has exaggerated the effect size compared with the studies that are done in later years. 

Plot of effect size as a function of publication year (online) - this was chosen as the online year was published first than the printed. Points are scaled in relation to their precision inverse sampling variance. Small points indicate effects with low precision or high sampling variance. (That is how it was shown in the html in week 10.) From this plot the key features about this time-lag bias was that it presents a clear positive relationship with year. Also there are earlier year studies that have much higher sampling variance (i.e., low precision), just like we might expect. In addition these early studies appear to have a far higher (Exaggerated) effect size compared with studies that are done in later years. 

There does appear to be a clear negative relationship with year.
Also of note are that the earlier year studies have much higher sampling variance (i.e., lower precision), just like we might expect.
These early studies appear to have a far higher (exaggerated) effect size compared with studies that are done in later years.

### Task 9: Formal meta-regression model that includes year as a moderator (fixed effect) to test for time-lag bias
```{r}
# Including sampling variance and year as moderators to account for both!
time_bias_meta <- rma.mv(effect.size ~ year.online, V = sampling.variance,
                    random = list(~1|Species,
                                  ~1|Study,
                                  ~1|residual), 
                    test = "t", dfs = "contain", 
                    data = fun_a)

# How much variation does time when results were published explain in Zr?
r2_tb <- orchaRd::r2_ml(time_bias_meta)
r2_tb
```
### Task 10: Formal meta-regression model that includes inverse sampling variance to test for file-drawer biases

```{r}
# Centering the sampling variance and the year (mean) to account 
fun_a <- fun_a %>% mutate(Year_center = year.online - mean(year.online)) %>% mutate(sv_center = sampling.variance - mean(sampling.variance))

file_drawer_meta <- rma.mv(effect.size ~ Year_center + 1/sv_center, V = sampling.variance,
                    random = list(~1|Species,
                                  ~1|Study,
                                  ~1|residual), 
                    test = "t", dfs = "contain", 
                    data = fun_a)

# How much variation does time when results were published explain in Zr?
r2_tb <- orchaRd::r2_ml(file_drawer_meta)
r2_tb 
```

### Task 11: Potential publication bias based on meta-regression results. 
What type of publication bias, if any, appears to be present in the data? If present, what does it mean and what might be contributing to such bias?

This model (task 9) demonstrates from the variation model it will show the percentage of the effect size. The marginal value was about 0.022 which indicates that the variation of the fixed effects/ moderators explains the model very low. Also, the conditional value was around 0.11 suggesting that they account for both the fixed and random effects of year in effect size. This meta-regression model includes a year as a moderator in the test for time-lag bias shows that there was no expected publication bias.

This meta-regression model  (task 10) including the inverse sampling variance the overall mean correlation value was found. This is because the marginal was 0.02 and the conditional was 0.11 this once again presents a similar result as discussed in the previous task.Suggesting that not of the species and study and residual had no correlation between them. Also it demonstrates how there is no publication bias. The mean effect size decrease indicates that there were more studies and so there is low chance of publication biases. This presents with the evidence for no publication bias as the slope estimate for sampling variance was not significant. For instance there was uncertainty around the estimate with a low set of studies that did not result in the expected correlation to be an average 0.

Thus, coming to conclusion that the data analysis of the different reef fish species having no strong evidence that increased acidification had effects on behaviour this result seems to be accurate as according to this meta-analysis it presents with no/ low publication bias. 

Thus, this comes to show that the effect of ocean acifification on behaviour the possible publication bias were probability biological, methodological, publication practice factors that explains the variation in effect size. 

### Task 12: Comparation between meta-analysis of the updated and by Clement et al. (2022) in contribution to publication bias
describe using references to existing papers what concerns have been raised?

  In the updated meta-analysis the conclusion was that there was no publication bias while the paper did have publication bias. First of all unlike the updated, the paper's meta-analyses the absolute lnRR values were calculated it was found that it was decreasing throughout the period causing the mean effect size to decrease. Also observing the weighted mean effect size magnitudes lnRR across the years, the updated meta-analysis not all data were included to the data, as the outliers of the mean effect size were not included. Thus resulting the flow of the forest plot and the time-lag bias plot to increase.



# ii) Reproducibility
(My GitHub Repository)[https://github.com/Han3207/Meta-analysis_OA.git]

